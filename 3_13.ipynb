{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 18\n",
    "\n",
    "Bisher haben wir uns lediglich lineare Klassifikatoren angeschaut. Jetzt möchten wir uns auch nicht-lineare Klassifikatoren anschauen. Aber dann wird es schwierig, immer die Ableitung zu berechnen. Da hilft uns Pytorch. Pytorch ist ganz ähnlich zu Numpy, ist allerdings für Maschinelles Lernen optimiert und kann zum Beispiel Gradienten selbstständig berechnen. Unten seht ihr ein komplettes Beispiel, wie man mit Hilfe von Pytorch ein lineares Modell wie im vorherigen Schritt optimieren kann. Versucht die besten Lernraten lr und die richtige Anzahl an Schritten zu finden, damit ihr euer Klassifikator eine Genauigkeit von über 80% bekommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Daten laden\n",
    "D = np.load('data/train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def classifier(D, D_test):\n",
    "    # konvertiere die Daten in einen Torch Tensor (getrennt in Eigenschaften und Labels)\n",
    "    X = np.hstack([np.ones_like(D[:, 0])[:, None], D[:, :-1]])\n",
    "    X = torch.from_numpy(X).float()\n",
    "    y = torch.from_numpy(D[:, -1]).float()\n",
    "\n",
    "    # definiere die Parameter\n",
    "    w = torch.randn(14, requires_grad=True)\n",
    "\n",
    "    # definiere die Kostenfunktion\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # definiere den Gradientabstieg\n",
    "    optimizer = torch.optim.SGD([w], lr=0.0001, momentum=0.9)\n",
    "\n",
    "    for i in range(10000):   # loop over the dataset multiple times\n",
    "\n",
    "        # Stelle sicher, dass keine Gradienten aus vorherigen Schritten gecached sind.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Berechne den Output von deinem Modell\n",
    "        # Diesmal ohne Sigmoid, das ist bei Torch in der Kostenfunktion bereits enthalten\n",
    "        outputs = torch.matmul(X, w)\n",
    "\n",
    "        # Wert der Kostenfunktion\n",
    "        kosten = criterion(outputs, y)\n",
    "\n",
    "        # Berechne die Gradienten für die Parameter\n",
    "        kosten.backward()\n",
    "\n",
    "        # Ändere die Parameter in Richtung der Gradienten\n",
    "        optimizer.step()\n",
    "\n",
    "        # Vorhergesagte labels\n",
    "        yhat = outputs.detach().numpy() > 0\n",
    "\n",
    "        # Messe die Genauigkeit des Klassifikators\n",
    "        acc = np.mean(yhat == y.numpy())\n",
    "\n",
    "        print(f'Iteration {i}: Kosten {kosten.item()}, Genauigkeit {acc}')\n",
    "        \n",
    "    # am Ende versuchen wir die Datenpunkte in D_test zu klassifizieren und auszugeben\n",
    "    X_test = np.hstack([np.ones_like(D_test[:, 0])[:, None], D_test])\n",
    "    X_test = torch.from_numpy(X_test).float()\n",
    "    outputs_test = torch.matmul(X_test, w)\n",
    "    \n",
    "    labels_test = outputs_test.numpy() > 0\n",
    "    \n",
    "    return labels_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
